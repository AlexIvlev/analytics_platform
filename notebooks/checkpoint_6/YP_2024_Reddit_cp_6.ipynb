{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet -q\n",
        "!pip install tab_transformer_pytorch -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__sIZkosFcUO",
        "outputId": "9f658748-a5ea-4c1a-d602-31bcaf4ba9ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m835.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mWW8pRihlnke"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from tab_transformer_pytorch import TabTransformer\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read and preprocess the data"
      ],
      "metadata": {
        "id": "A9-0gsZBqBeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMCUBHSImaJU",
        "outputId": "f8521a63-d90a-45ca-ccad-df33fb1c51f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"/content/drive/MyDrive/datasets/reddit_parser_2024_12_06_prices.parquet\")"
      ],
      "metadata": {
        "id": "CB1aO37zlsgk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_parquet('/content/drive/MyDrive/datasets/reddit_parser_2025_03_10_processed.parquet')"
      ],
      "metadata": {
        "id": "Vkh7-vQ08r0d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape, df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB32EYRG9pON",
        "outputId": "0de46678-799e-42eb-a88f-59dba8f82ad3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8416, 21), (881, 21))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    df['target'] = np.where(df['price_1d'] > df['created_price'], 1, 0)\n",
        "\n",
        "    drop_cols = ['id', 'title', 'url', 'created_utc', 'parsed_utc',\n",
        "                 'text', 'parent_id', 'clean_text', 'processed_text',\n",
        "                 'entities', 'tickers', 'price_1d', 'doc_embedding']\n",
        "\n",
        "    df = df.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "    df.rename(columns={\"processed_text_length\": \"text_length\"}, errors='ignore', inplace=True)\n",
        "\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = preprocess_data(df)\n",
        "df2 = preprocess_data(df2)"
      ],
      "metadata": {
        "id": "so9bXGVhlsgl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JUMBb4YgmgQu",
        "outputId": "b2321933-c5de-470a-8c49-dfd09e210f8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   subreddit  score  num_comments        type  text_length  sentiment_scores  \\\n",
              "0  investing      3           0.0     comment          594           -0.0772   \n",
              "1  investing      1           0.0     comment           12            0.0000   \n",
              "2  investing      4           0.0     comment          433           -0.6652   \n",
              "3  investing    102          92.0  submission         1362           -0.9131   \n",
              "4  investing      1           0.0     comment          332           -0.1280   \n",
              "\n",
              "  ticker  created_price  target  \n",
              "0   PATH      14.940000       0  \n",
              "1    KAR      20.250000       0  \n",
              "2    QQQ     521.799988       1  \n",
              "3     AI      37.490002       1  \n",
              "4     AI      37.490002       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-636a0d8d-bcbf-45c7-a305-6bd81b455a71\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>type</th>\n",
              "      <th>text_length</th>\n",
              "      <th>sentiment_scores</th>\n",
              "      <th>ticker</th>\n",
              "      <th>created_price</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>investing</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>comment</td>\n",
              "      <td>594</td>\n",
              "      <td>-0.0772</td>\n",
              "      <td>PATH</td>\n",
              "      <td>14.940000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>investing</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>comment</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>KAR</td>\n",
              "      <td>20.250000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>investing</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>comment</td>\n",
              "      <td>433</td>\n",
              "      <td>-0.6652</td>\n",
              "      <td>QQQ</td>\n",
              "      <td>521.799988</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>investing</td>\n",
              "      <td>102</td>\n",
              "      <td>92.0</td>\n",
              "      <td>submission</td>\n",
              "      <td>1362</td>\n",
              "      <td>-0.9131</td>\n",
              "      <td>AI</td>\n",
              "      <td>37.490002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>investing</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>comment</td>\n",
              "      <td>332</td>\n",
              "      <td>-0.1280</td>\n",
              "      <td>AI</td>\n",
              "      <td>37.490002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-636a0d8d-bcbf-45c7-a305-6bd81b455a71')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-636a0d8d-bcbf-45c7-a305-6bd81b455a71 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-636a0d8d-bcbf-45c7-a305-6bd81b455a71');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a78ff3f5-e082-4883-accf-5b7962cd95e3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a78ff3f5-e082-4883-accf-5b7962cd95e3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a78ff3f5-e082-4883-accf-5b7962cd95e3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8416,\n  \"fields\": [\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"investing\",\n          \"stocks\",\n          \"algotrading\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 165,\n        \"min\": -40,\n        \"max\": 12015,\n        \"num_unique_values\": 279,\n        \"samples\": [\n          55,\n          374,\n          127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.26948409283589,\n        \"min\": 0.0,\n        \"max\": 1654.0,\n        \"num_unique_values\": 159,\n        \"samples\": [\n          33.0,\n          62.0,\n          436.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"submission\",\n          \"comment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 971,\n        \"min\": 1,\n        \"max\": 29179,\n        \"num_unique_values\": 1549,\n        \"samples\": [\n          1735,\n          908\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5174077143580027,\n        \"min\": -0.9875,\n        \"max\": 0.9999,\n        \"num_unique_values\": 2590,\n        \"samples\": [\n          0.7684,\n          0.1511\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 810,\n        \"samples\": [\n          \"CROX\",\n          \"MSN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 810.7749294261544,\n        \"min\": 0.00039999998989515007,\n        \"max\": 6098.240234375,\n        \"num_unique_values\": 3759,\n        \"samples\": [\n          71.55999755859375,\n          69.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqk-DsBGrovO",
        "outputId": "e9428601-7da8-4bcd-8489-5d7571e52d42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8416 entries, 0 to 8415\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   subreddit         8416 non-null   object \n",
            " 1   score             8416 non-null   int64  \n",
            " 2   num_comments      8416 non-null   float64\n",
            " 3   type              8416 non-null   object \n",
            " 4   text_length       8416 non-null   int64  \n",
            " 5   sentiment_scores  8416 non-null   float64\n",
            " 6   ticker            8416 non-null   object \n",
            " 7   created_price     8416 non-null   float64\n",
            " 8   target            8416 non-null   int64  \n",
            "dtypes: float64(3), int64(3), object(3)\n",
            "memory usage: 591.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df, df2], axis=0)"
      ],
      "metadata": {
        "id": "atw1hroj-BYJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "tCG8lekFqGVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X_num: np.ndarray, X_cat: np.ndarray, y: np.ndarray):\n",
        "        self.X_num = torch.from_numpy(X_num).float()\n",
        "        self.X_cat = torch.from_numpy(X_cat).long()\n",
        "        self.y = torch.from_numpy(y).float().unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_num[idx], self.X_cat[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "IERrdLLjqHQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularMLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_numeric: int,\n",
        "                 cat_cardinalities: list,\n",
        "                 embedding_dims: list,\n",
        "                #  hidden_layers: list = [128, 64, 32],\n",
        "                #  hidden_layers: list = [64, 32],\n",
        "                 hidden_layers: list = [64, 32, 16],\n",
        "                 dropout: float = 0.4):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(cat_cardinalities) == len(embedding_dims)\n",
        "\n",
        "        self.embeddings = nn.ModuleList([\n",
        "            nn.Embedding(card, dim)\n",
        "            for card, dim in zip(cat_cardinalities, embedding_dims)\n",
        "        ])\n",
        "        emb_out_dim = sum(embedding_dims)\n",
        "        input_dim = num_numeric + emb_out_dim\n",
        "\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for h_dim in hidden_layers:\n",
        "            layers.append(nn.Linear(in_dim, h_dim))\n",
        "            layers.append(nn.BatchNorm1d(h_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = h_dim\n",
        "        layers.append(nn.Linear(in_dim, 1))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x_num, x_cat):\n",
        "        # numeric: (batch, num_numeric)\n",
        "        # cat: (batch, num_cats)\n",
        "        embedded = []\n",
        "        for i, emb in enumerate(self.embeddings):\n",
        "            embedded.append(emb(x_cat[:, i]))\n",
        "        x = torch.cat(embedded + [x_num], dim=1)\n",
        "        logits = self.model(x)\n",
        "        prob = torch.sigmoid(logits)\n",
        "        return prob"
      ],
      "metadata": {
        "id": "wOxWrtAiqeXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = ['score', 'num_comments', 'text_length', 'sentiment_scores', 'created_price']\n",
        "cat_features = ['subreddit', 'type', 'ticker']\n",
        "\n",
        "\n",
        "cat_maps = {}\n",
        "for col in cat_features:\n",
        "    df[col] = df[col].astype('category')\n",
        "    cat_maps[col] = df[col].cat.categories\n",
        "    df[col] = df[col].cat.codes"
      ],
      "metadata": {
        "id": "5sOv-yBNsGe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_num = scaler.fit_transform(df[num_features].values)\n",
        "X_cat = df[cat_features].values\n",
        "y = df['target'].values"
      ],
      "metadata": {
        "id": "FKd86yf6wh7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_num_train, X_num_val, X_cat_train, X_cat_val, y_train, y_val = train_test_split(\n",
        "    X_num, X_cat, y, test_size=0.2, random_state=69, stratify=y)"
      ],
      "metadata": {
        "id": "cjC22-7A0g2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TabularDataset(X_num_train, X_cat_train, y_train)\n",
        "val_ds   = TabularDataset(X_num_val,   X_cat_val,   y_val)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "WT3LaV6l0r2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cardinalities = [len(cat_maps[col]) for col in cat_features]\n",
        "\n",
        "# choose embedding dims: e.g. min(50, (card+1)//2)\n",
        "embedding_dims = [min(50, (card+1)//2) for card in cat_cardinalities]\n",
        "\n",
        "model = TabularMLP(\n",
        "    num_numeric=len(num_features),\n",
        "    cat_cardinalities=cat_cardinalities,\n",
        "    embedding_dims=embedding_dims,\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER7cs_C3q6p4",
        "outputId": "26dfbee0-a3fa-4987-dea0-d2ec1397deb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 50\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for xb_num, xb_cat, yb in train_loader:\n",
        "        xb_num, xb_cat, yb = xb_num.to(device), xb_cat.to(device), yb.to(device)\n",
        "        preds = model(xb_num, xb_cat)\n",
        "        loss = criterion(preds, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * xb_num.size(0)\n",
        "        preds_bin = (preds.detach().cpu().numpy() > 0.5).astype(int).flatten()\n",
        "        all_preds.extend(preds_bin.tolist())\n",
        "        all_labels.extend(yb.cpu().numpy().astype(int).flatten().tolist())\n",
        "\n",
        "    train_loss /= len(train_ds)\n",
        "    train_acc = accuracy_score(all_labels, all_preds)\n",
        "    train_f1  = f1_score(all_labels, all_preds)\n",
        "    print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb_num, xb_cat, yb in val_loader:\n",
        "                xb_num, xb_cat, yb = xb_num.to(device), xb_cat.to(device), yb.to(device)\n",
        "                preds = model(xb_num, xb_cat)\n",
        "                val_loss += criterion(preds, yb).item() * xb_num.size(0)\n",
        "                preds_bin = (preds.cpu().numpy() > 0.5).astype(int).flatten()\n",
        "                val_preds.extend(preds_bin.tolist())\n",
        "                val_labels.extend(yb.cpu().numpy().astype(int).flatten().tolist())\n",
        "\n",
        "        val_loss /= len(val_ds)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_f1  = f1_score(val_labels, val_preds)\n",
        "        print(f\"----- Validation @Epoch {epoch} | Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f} -----\")\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'scaler': scaler,\n",
        "    'cat_maps': cat_maps\n",
        "}, 'tabular_mlp.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIvHrqUdxljI",
        "outputId": "a629aa74-ace4-4f2a-e06c-94cef9fa5835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.7022 | Acc: 0.5147 | F1: 0.4310\n",
            "Epoch 2 | Train Loss: 0.6954 | Acc: 0.5233 | F1: 0.4644\n",
            "Epoch 3 | Train Loss: 0.6884 | Acc: 0.5335 | F1: 0.4591\n",
            "Epoch 4 | Train Loss: 0.6877 | Acc: 0.5362 | F1: 0.4721\n",
            "Epoch 5 | Train Loss: 0.6856 | Acc: 0.5510 | F1: 0.4886\n",
            "Epoch 6 | Train Loss: 0.6823 | Acc: 0.5634 | F1: 0.4943\n",
            "Epoch 7 | Train Loss: 0.6818 | Acc: 0.5596 | F1: 0.5010\n",
            "Epoch 8 | Train Loss: 0.6823 | Acc: 0.5564 | F1: 0.4984\n",
            "Epoch 9 | Train Loss: 0.6790 | Acc: 0.5680 | F1: 0.5005\n",
            "Epoch 10 | Train Loss: 0.6762 | Acc: 0.5735 | F1: 0.5148\n",
            "----- Validation @Epoch 10 | Loss: 0.6855 | Acc: 0.5382 | F1: 0.4991 -----\n",
            "Epoch 11 | Train Loss: 0.6749 | Acc: 0.5762 | F1: 0.5269\n",
            "Epoch 12 | Train Loss: 0.6726 | Acc: 0.5826 | F1: 0.5263\n",
            "Epoch 13 | Train Loss: 0.6656 | Acc: 0.5930 | F1: 0.5514\n",
            "Epoch 14 | Train Loss: 0.6654 | Acc: 0.5932 | F1: 0.5521\n",
            "Epoch 15 | Train Loss: 0.6586 | Acc: 0.6031 | F1: 0.5772\n",
            "Epoch 16 | Train Loss: 0.6534 | Acc: 0.6097 | F1: 0.5798\n",
            "Epoch 17 | Train Loss: 0.6498 | Acc: 0.6162 | F1: 0.5809\n",
            "Epoch 18 | Train Loss: 0.6468 | Acc: 0.6203 | F1: 0.5921\n",
            "Epoch 19 | Train Loss: 0.6435 | Acc: 0.6292 | F1: 0.5995\n",
            "Epoch 20 | Train Loss: 0.6400 | Acc: 0.6218 | F1: 0.5854\n",
            "----- Validation @Epoch 20 | Loss: 0.6915 | Acc: 0.5565 | F1: 0.5009 -----\n",
            "Epoch 21 | Train Loss: 0.6364 | Acc: 0.6302 | F1: 0.5875\n",
            "Epoch 22 | Train Loss: 0.6333 | Acc: 0.6317 | F1: 0.6026\n",
            "Epoch 23 | Train Loss: 0.6318 | Acc: 0.6289 | F1: 0.5901\n",
            "Epoch 24 | Train Loss: 0.6296 | Acc: 0.6277 | F1: 0.5858\n",
            "Epoch 25 | Train Loss: 0.6290 | Acc: 0.6209 | F1: 0.5799\n",
            "Epoch 26 | Train Loss: 0.6221 | Acc: 0.6314 | F1: 0.5702\n",
            "Epoch 27 | Train Loss: 0.6244 | Acc: 0.6380 | F1: 0.5995\n",
            "Epoch 28 | Train Loss: 0.6212 | Acc: 0.6347 | F1: 0.5948\n",
            "Epoch 29 | Train Loss: 0.6172 | Acc: 0.6417 | F1: 0.6028\n",
            "Epoch 30 | Train Loss: 0.6199 | Acc: 0.6336 | F1: 0.5834\n",
            "----- Validation @Epoch 30 | Loss: 0.7064 | Acc: 0.5543 | F1: 0.4867 -----\n",
            "Epoch 31 | Train Loss: 0.6214 | Acc: 0.6322 | F1: 0.5932\n",
            "Epoch 32 | Train Loss: 0.6168 | Acc: 0.6392 | F1: 0.5918\n",
            "Epoch 33 | Train Loss: 0.6159 | Acc: 0.6415 | F1: 0.5980\n",
            "Epoch 34 | Train Loss: 0.6088 | Acc: 0.6394 | F1: 0.5939\n",
            "Epoch 35 | Train Loss: 0.6128 | Acc: 0.6384 | F1: 0.5940\n",
            "Epoch 36 | Train Loss: 0.6091 | Acc: 0.6386 | F1: 0.6037\n",
            "Epoch 37 | Train Loss: 0.6013 | Acc: 0.6474 | F1: 0.6082\n",
            "Epoch 38 | Train Loss: 0.6110 | Acc: 0.6427 | F1: 0.6050\n",
            "Epoch 39 | Train Loss: 0.6106 | Acc: 0.6421 | F1: 0.5942\n",
            "Epoch 40 | Train Loss: 0.6031 | Acc: 0.6431 | F1: 0.6029\n",
            "----- Validation @Epoch 40 | Loss: 0.7101 | Acc: 0.5473 | F1: 0.5394 -----\n",
            "Epoch 41 | Train Loss: 0.6011 | Acc: 0.6443 | F1: 0.6164\n",
            "Epoch 42 | Train Loss: 0.6033 | Acc: 0.6445 | F1: 0.6068\n",
            "Epoch 43 | Train Loss: 0.5966 | Acc: 0.6492 | F1: 0.6232\n",
            "Epoch 44 | Train Loss: 0.5963 | Acc: 0.6438 | F1: 0.6112\n",
            "Epoch 45 | Train Loss: 0.5976 | Acc: 0.6446 | F1: 0.6100\n",
            "Epoch 46 | Train Loss: 0.5962 | Acc: 0.6543 | F1: 0.6116\n",
            "Epoch 47 | Train Loss: 0.5937 | Acc: 0.6525 | F1: 0.5998\n",
            "Epoch 48 | Train Loss: 0.5936 | Acc: 0.6531 | F1: 0.6127\n",
            "Epoch 49 | Train Loss: 0.5972 | Acc: 0.6443 | F1: 0.6020\n",
            "Epoch 50 | Train Loss: 0.5861 | Acc: 0.6570 | F1: 0.6139\n",
            "----- Validation @Epoch 50 | Loss: 0.7540 | Acc: 0.5478 | F1: 0.4760 -----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TabNet\n"
      ],
      "metadata": {
        "id": "GpuO50FpDTvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'target'\n",
        "categorical_features = ['subreddit', 'type', 'ticker']\n",
        "feature_cols = ['score', 'num_comments', 'text_length', 'sentiment_scores', 'created_price'] + categorical_features\n",
        "numerical_features = [col for col in feature_cols if col not in categorical_features]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "ttXzg-w-DVVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[target_col].values\n",
        "X = df[feature_cols].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=69, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "wSqf3hvrL0QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "num_idxs = [feature_cols.index(col) for col in numerical_features]\n",
        "\n",
        "X_train_num = scaler.fit_transform(X_train[:, num_idxs])\n",
        "X_val_num = scaler.transform(X_val[:, num_idxs])\n",
        "\n",
        "X_train_pre = np.hstack([X_train_num, X_train[:, len(numerical_features):]])\n",
        "X_val_pre   = np.hstack([X_val_num,   X_val[:,   len(numerical_features):]])\n",
        "\n",
        "cat_idxs = [i + len(numerical_features) for i in range(len(categorical_features))]\n",
        "cat_dims = [int(df[col].nunique()) for col in categorical_features]"
      ],
      "metadata": {
        "id": "Td6n0Q0eMFOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=16,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.5},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='entmax'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6rGlXGMRQs",
        "outputId": "a9b70069-7b12-4bb9-f6e2-566dc62494cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 is not implemented for TabNet, so we use AUC instead"
      ],
      "metadata": {
        "id": "y9w77zmzPgw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train_pre, y_train,\n",
        "    eval_set=[(X_train_pre, y_train), (X_val_pre, y_val)],\n",
        "    eval_name=['train','valid'],\n",
        "    eval_metric=['accuracy','auc'],\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=64,\n",
        "    num_workers=0,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsgKC5V5MV7p",
        "outputId": "7f358fdc-a0e5-4445-99e9-0e66450b5c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.80084 | train_accuracy: 0.50758 | train_auc: 0.5033  | valid_accuracy: 0.49941 | valid_auc: 0.50226 |  0:00:01s\n",
            "epoch 1  | loss: 0.70075 | train_accuracy: 0.50936 | train_auc: 0.50462 | valid_accuracy: 0.50772 | valid_auc: 0.51122 |  0:00:02s\n",
            "epoch 2  | loss: 0.69562 | train_accuracy: 0.50787 | train_auc: 0.52121 | valid_accuracy: 0.5101  | valid_auc: 0.53032 |  0:00:04s\n",
            "epoch 3  | loss: 0.69481 | train_accuracy: 0.51099 | train_auc: 0.53944 | valid_accuracy: 0.50713 | valid_auc: 0.52105 |  0:00:05s\n",
            "epoch 4  | loss: 0.69406 | train_accuracy: 0.51411 | train_auc: 0.54411 | valid_accuracy: 0.50416 | valid_auc: 0.5346  |  0:00:07s\n",
            "epoch 5  | loss: 0.69296 | train_accuracy: 0.53075 | train_auc: 0.55399 | valid_accuracy: 0.51781 | valid_auc: 0.54125 |  0:00:08s\n",
            "epoch 6  | loss: 0.69061 | train_accuracy: 0.53491 | train_auc: 0.56092 | valid_accuracy: 0.51544 | valid_auc: 0.54207 |  0:00:10s\n",
            "epoch 7  | loss: 0.69071 | train_accuracy: 0.55496 | train_auc: 0.5841  | valid_accuracy: 0.5291  | valid_auc: 0.538   |  0:00:12s\n",
            "epoch 8  | loss: 0.68439 | train_accuracy: 0.57249 | train_auc: 0.61615 | valid_accuracy: 0.54097 | valid_auc: 0.55419 |  0:00:13s\n",
            "epoch 9  | loss: 0.67282 | train_accuracy: 0.59863 | train_auc: 0.65071 | valid_accuracy: 0.53444 | valid_auc: 0.55862 |  0:00:15s\n",
            "epoch 10 | loss: 0.6507  | train_accuracy: 0.61631 | train_auc: 0.67498 | valid_accuracy: 0.55938 | valid_auc: 0.5884  |  0:00:16s\n",
            "epoch 11 | loss: 0.63813 | train_accuracy: 0.63532 | train_auc: 0.69228 | valid_accuracy: 0.57007 | valid_auc: 0.59467 |  0:00:18s\n",
            "epoch 12 | loss: 0.62991 | train_accuracy: 0.64097 | train_auc: 0.70549 | valid_accuracy: 0.57007 | valid_auc: 0.58602 |  0:00:19s\n",
            "epoch 13 | loss: 0.62062 | train_accuracy: 0.64825 | train_auc: 0.71644 | valid_accuracy: 0.56888 | valid_auc: 0.6005  |  0:00:20s\n",
            "epoch 14 | loss: 0.61556 | train_accuracy: 0.64156 | train_auc: 0.71015 | valid_accuracy: 0.5772  | valid_auc: 0.60585 |  0:00:22s\n",
            "epoch 15 | loss: 0.60873 | train_accuracy: 0.65092 | train_auc: 0.72794 | valid_accuracy: 0.56888 | valid_auc: 0.604   |  0:00:23s\n",
            "epoch 16 | loss: 0.60504 | train_accuracy: 0.653   | train_auc: 0.72805 | valid_accuracy: 0.57423 | valid_auc: 0.60299 |  0:00:25s\n",
            "epoch 17 | loss: 0.59842 | train_accuracy: 0.64498 | train_auc: 0.73253 | valid_accuracy: 0.5576  | valid_auc: 0.60312 |  0:00:27s\n",
            "epoch 18 | loss: 0.59855 | train_accuracy: 0.6582  | train_auc: 0.7407  | valid_accuracy: 0.58314 | valid_auc: 0.6084  |  0:00:28s\n",
            "epoch 19 | loss: 0.59328 | train_accuracy: 0.66102 | train_auc: 0.74435 | valid_accuracy: 0.57245 | valid_auc: 0.60014 |  0:00:30s\n",
            "epoch 20 | loss: 0.58247 | train_accuracy: 0.66414 | train_auc: 0.74857 | valid_accuracy: 0.57898 | valid_auc: 0.60515 |  0:00:31s\n",
            "epoch 21 | loss: 0.57856 | train_accuracy: 0.66592 | train_auc: 0.75027 | valid_accuracy: 0.58195 | valid_auc: 0.60414 |  0:00:33s\n",
            "epoch 22 | loss: 0.57749 | train_accuracy: 0.66949 | train_auc: 0.75218 | valid_accuracy: 0.57482 | valid_auc: 0.60907 |  0:00:34s\n",
            "epoch 23 | loss: 0.5734  | train_accuracy: 0.67246 | train_auc: 0.75374 | valid_accuracy: 0.5677  | valid_auc: 0.60522 |  0:00:36s\n",
            "epoch 24 | loss: 0.57548 | train_accuracy: 0.66889 | train_auc: 0.75303 | valid_accuracy: 0.58076 | valid_auc: 0.60924 |  0:00:37s\n",
            "epoch 25 | loss: 0.5709  | train_accuracy: 0.66889 | train_auc: 0.75621 | valid_accuracy: 0.5772  | valid_auc: 0.61065 |  0:00:39s\n",
            "epoch 26 | loss: 0.57148 | train_accuracy: 0.67335 | train_auc: 0.75868 | valid_accuracy: 0.57482 | valid_auc: 0.60891 |  0:00:41s\n",
            "epoch 27 | loss: 0.56951 | train_accuracy: 0.66771 | train_auc: 0.75727 | valid_accuracy: 0.5671  | valid_auc: 0.60341 |  0:00:43s\n",
            "epoch 28 | loss: 0.56663 | train_accuracy: 0.67157 | train_auc: 0.76178 | valid_accuracy: 0.58848 | valid_auc: 0.60838 |  0:00:44s\n",
            "epoch 29 | loss: 0.56585 | train_accuracy: 0.6784  | train_auc: 0.76714 | valid_accuracy: 0.57304 | valid_auc: 0.60679 |  0:00:45s\n",
            "epoch 30 | loss: 0.56077 | train_accuracy: 0.68137 | train_auc: 0.76801 | valid_accuracy: 0.5766  | valid_auc: 0.60433 |  0:00:47s\n",
            "epoch 31 | loss: 0.56267 | train_accuracy: 0.68271 | train_auc: 0.76856 | valid_accuracy: 0.57542 | valid_auc: 0.60434 |  0:00:48s\n",
            "epoch 32 | loss: 0.55717 | train_accuracy: 0.68286 | train_auc: 0.77069 | valid_accuracy: 0.57007 | valid_auc: 0.60521 |  0:00:50s\n",
            "epoch 33 | loss: 0.55508 | train_accuracy: 0.68419 | train_auc: 0.7717  | valid_accuracy: 0.57067 | valid_auc: 0.60455 |  0:00:51s\n",
            "epoch 34 | loss: 0.55501 | train_accuracy: 0.68806 | train_auc: 0.77467 | valid_accuracy: 0.57363 | valid_auc: 0.60549 |  0:00:53s\n",
            "epoch 35 | loss: 0.5515  | train_accuracy: 0.68598 | train_auc: 0.7736  | valid_accuracy: 0.57423 | valid_auc: 0.60977 |  0:00:55s\n",
            "\n",
            "Early stopping occurred at epoch 35 with best_epoch = 25 and best_valid_auc = 0.61065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_val_pre)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "print(f\"Validation F1 Score: {f1:.4f}\")\n",
        "\n",
        "torch.save(clf, 'tabnet_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvTEcDk3MZ9m",
        "outputId": "ca7f9325-90d6-4bf0-e507-d69c7f70a99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5772\n",
            "Validation F1 Score: 0.6118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tab Transformer"
      ],
      "metadata": {
        "id": "m-lgoWeCNWHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, X_num, X_cat, y):\n",
        "        self.X_num = torch.from_numpy(X_num).float()\n",
        "        self.X_cat = torch.from_numpy(X_cat).long()\n",
        "        self.y = torch.from_numpy(y).float().unsqueeze(1)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X_num[idx], self.X_cat[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "03kGnwG0GP1m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'target'\n",
        "categorical_features = ['subreddit','type','ticker']\n",
        "feature_cols = ['score','num_comments','text_length','sentiment_scores','created_price'] + categorical_features\n",
        "numerical_features = [c for c in feature_cols if c not in categorical_features]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "X = df[feature_cols].values\n",
        "y = df[target_col].values\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "htEaK2zkFwbK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "num_idxs = [feature_cols.index(c) for c in numerical_features]\n",
        "X_train_num = scaler.fit_transform(X_train[:, num_idxs])\n",
        "X_val_num = scaler.transform(X_val[:, num_idxs])\n",
        "\n",
        "cat_idxs = [feature_cols.index(c) for c in categorical_features]\n",
        "X_train_cat = X_train[:, cat_idxs].astype(int)\n",
        "X_val_cat = X_val[:, cat_idxs].astype(int)\n",
        "\n",
        "train_cont_tensor = torch.tensor(X_train_num, dtype=torch.float)\n",
        "cont_mean_std = torch.stack([train_cont_tensor.mean(0), train_cont_tensor.std(0)], dim=1)\n"
      ],
      "metadata": {
        "id": "SF8A99KeEyZb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_continuous = len(numerical_features)\n",
        "categories = tuple(int(df[c].nunique()) for c in categorical_features)\n",
        "\n",
        "\n",
        "transformer = TabTransformer(\n",
        "    categories=categories,\n",
        "    num_continuous=num_continuous,\n",
        "    dim=32,\n",
        "    depth=6,\n",
        "    heads=8,\n",
        "    attn_dropout=0.1,\n",
        "    ff_dropout=0.1,\n",
        "    mlp_hidden_mults=(4,2),\n",
        "    mlp_act=nn.ReLU(),\n",
        "    dim_out=1,\n",
        "    continuous_mean_std=cont_mean_std\n",
        ")\n",
        "model = transformer\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "v8nONIniOBUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TabularDataset(X_train_num, X_train_cat, y_train)\n",
        "val_ds   = TabularDataset(X_val_num,   X_val_cat,   y_val)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "OHi15OLaFpgr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4byD4udVOQCb",
        "outputId": "654277b5-ba9c-40a7-a84e-b5763020f1c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_loss, preds, labs = 0.0, [], []\n",
        "    for xb_num, xb_cat, yb in train_loader:\n",
        "        xb_num, xb_cat, yb = xb_num.to(device), xb_cat.to(device), yb.to(device)\n",
        "        logits = model(xb_cat, xb_num)\n",
        "        loss = criterion(logits, yb)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        train_loss += loss.item() * xb_num.size(0)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds.extend((probs.detach().cpu().numpy()>0.5).astype(int).flatten().tolist())\n",
        "        labs.extend(yb.cpu().numpy().astype(int).flatten().tolist())\n",
        "    train_loss /= len(train_ds)\n",
        "    train_acc = accuracy_score(labs, preds)\n",
        "    train_f1 = f1_score(labs, preds)\n",
        "    print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        val_loss, vpreds, vlabs = 0.0, [], []\n",
        "        with torch.no_grad():\n",
        "            for xb_num, xb_cat, yb in val_loader:\n",
        "                xb_num, xb_cat, yb = xb_num.to(device), xb_cat.to(device), yb.to(device)\n",
        "                logits = model(xb_cat, xb_num)\n",
        "                val_loss += criterion(logits, yb).item() * xb_num.size(0)\n",
        "                probs = torch.sigmoid(logits)\n",
        "                vpreds.extend((probs.cpu().numpy()>0.5).astype(int).flatten().tolist())\n",
        "                vlabs.extend(yb.cpu().numpy().astype(int).flatten().tolist())\n",
        "        val_loss /= len(val_ds)\n",
        "        val_acc = accuracy_score(vlabs, vpreds)\n",
        "        val_f1 = f1_score(vlabs, vpreds)\n",
        "        print(f\"--- Val @Epoch {epoch} | Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f} ---\")\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "if epoch == EPOCHS:\n",
        "    torch.save(model.state_dict(), 'tabtransformer_lucidrains.pth')\n",
        "    joblib.dump(scaler, 'scaler_tt.pkl')\n",
        "    joblib.dump(label_encoders, 'label_encoders_tt.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3jhCF_wOTlR",
        "outputId": "9184a6d3-56ee-48ff-8e33-18bf81bf900f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.6997 | Acc: 0.5290 | F1: 0.4307\n",
            "Epoch 2 | Train Loss: 0.6817 | Acc: 0.5592 | F1: 0.4623\n",
            "Epoch 3 | Train Loss: 0.6728 | Acc: 0.5818 | F1: 0.5113\n",
            "Epoch 4 | Train Loss: 0.6657 | Acc: 0.5888 | F1: 0.5088\n",
            "Epoch 5 | Train Loss: 0.6608 | Acc: 0.5982 | F1: 0.5497\n",
            "Epoch 6 | Train Loss: 0.6493 | Acc: 0.6048 | F1: 0.5548\n",
            "Epoch 7 | Train Loss: 0.6422 | Acc: 0.6141 | F1: 0.5633\n",
            "Epoch 8 | Train Loss: 0.6316 | Acc: 0.6177 | F1: 0.5702\n",
            "Epoch 9 | Train Loss: 0.6205 | Acc: 0.6312 | F1: 0.5974\n",
            "Epoch 10 | Train Loss: 0.6110 | Acc: 0.6368 | F1: 0.5892\n",
            "--- Val @Epoch 10 | Loss: 0.6959 | Acc: 0.5785 | F1: 0.5063 ---\n",
            "Epoch 11 | Train Loss: 0.6012 | Acc: 0.6460 | F1: 0.6066\n",
            "Epoch 12 | Train Loss: 0.5962 | Acc: 0.6474 | F1: 0.6141\n",
            "Epoch 13 | Train Loss: 0.5857 | Acc: 0.6538 | F1: 0.6076\n",
            "Epoch 14 | Train Loss: 0.5763 | Acc: 0.6519 | F1: 0.6237\n",
            "Epoch 15 | Train Loss: 0.5717 | Acc: 0.6577 | F1: 0.6332\n",
            "Epoch 16 | Train Loss: 0.5705 | Acc: 0.6610 | F1: 0.6266\n",
            "Epoch 17 | Train Loss: 0.5610 | Acc: 0.6642 | F1: 0.6322\n",
            "Epoch 18 | Train Loss: 0.5586 | Acc: 0.6640 | F1: 0.6253\n",
            "Epoch 19 | Train Loss: 0.5552 | Acc: 0.6649 | F1: 0.6388\n",
            "Epoch 20 | Train Loss: 0.5529 | Acc: 0.6694 | F1: 0.6330\n",
            "--- Val @Epoch 20 | Loss: 0.8860 | Acc: 0.5688 | F1: 0.5559 ---\n",
            "Epoch 21 | Train Loss: 0.5526 | Acc: 0.6663 | F1: 0.6329\n",
            "Epoch 22 | Train Loss: 0.5455 | Acc: 0.6715 | F1: 0.6450\n",
            "Epoch 23 | Train Loss: 0.5408 | Acc: 0.6743 | F1: 0.6504\n",
            "Epoch 24 | Train Loss: 0.5407 | Acc: 0.6710 | F1: 0.6390\n",
            "Epoch 25 | Train Loss: 0.5424 | Acc: 0.6753 | F1: 0.6502\n",
            "Epoch 26 | Train Loss: 0.5469 | Acc: 0.6707 | F1: 0.6439\n",
            "Epoch 27 | Train Loss: 0.5354 | Acc: 0.6802 | F1: 0.6572\n",
            "Epoch 28 | Train Loss: 0.5331 | Acc: 0.6793 | F1: 0.6514\n",
            "Epoch 29 | Train Loss: 0.5289 | Acc: 0.6807 | F1: 0.6591\n",
            "Epoch 30 | Train Loss: 0.5273 | Acc: 0.6817 | F1: 0.6636\n",
            "--- Val @Epoch 30 | Loss: 1.0468 | Acc: 0.5591 | F1: 0.4919 ---\n",
            "Epoch 31 | Train Loss: 0.5252 | Acc: 0.6835 | F1: 0.6676\n",
            "Epoch 32 | Train Loss: 0.5242 | Acc: 0.6854 | F1: 0.6695\n",
            "Epoch 33 | Train Loss: 0.5187 | Acc: 0.6897 | F1: 0.6715\n",
            "Epoch 34 | Train Loss: 0.5161 | Acc: 0.6903 | F1: 0.6738\n",
            "Epoch 35 | Train Loss: 0.5112 | Acc: 0.6911 | F1: 0.6716\n",
            "Epoch 36 | Train Loss: 0.5115 | Acc: 0.6953 | F1: 0.6736\n",
            "Epoch 37 | Train Loss: 0.5102 | Acc: 0.6948 | F1: 0.6754\n",
            "Epoch 38 | Train Loss: 0.5035 | Acc: 0.6958 | F1: 0.6786\n",
            "Epoch 39 | Train Loss: 0.5017 | Acc: 0.6949 | F1: 0.6685\n",
            "Epoch 40 | Train Loss: 0.5031 | Acc: 0.7011 | F1: 0.6893\n",
            "--- Val @Epoch 40 | Loss: 1.0613 | Acc: 0.5581 | F1: 0.5276 ---\n",
            "Epoch 41 | Train Loss: 0.5057 | Acc: 0.6976 | F1: 0.6793\n",
            "Epoch 42 | Train Loss: 0.5058 | Acc: 0.6968 | F1: 0.6811\n",
            "Epoch 43 | Train Loss: 0.4995 | Acc: 0.7023 | F1: 0.6911\n",
            "Epoch 44 | Train Loss: 0.4997 | Acc: 0.7045 | F1: 0.6909\n",
            "Epoch 45 | Train Loss: 0.4991 | Acc: 0.7045 | F1: 0.6891\n",
            "Epoch 46 | Train Loss: 0.4924 | Acc: 0.7122 | F1: 0.6890\n",
            "Epoch 47 | Train Loss: 0.4881 | Acc: 0.7079 | F1: 0.6878\n",
            "Epoch 48 | Train Loss: 0.4847 | Acc: 0.7124 | F1: 0.6893\n",
            "Epoch 49 | Train Loss: 0.4810 | Acc: 0.7149 | F1: 0.6965\n",
            "Epoch 50 | Train Loss: 0.4803 | Acc: 0.7157 | F1: 0.6977\n",
            "--- Val @Epoch 50 | Loss: 1.3064 | Acc: 0.5538 | F1: 0.5363 ---\n"
          ]
        }
      ]
    }
  ]
}