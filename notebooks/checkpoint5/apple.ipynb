{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kQT2LDpAKyz",
        "outputId": "56030d6b-9503-4081-ad51-5b460f322bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import TextBlob\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.svm import SVR\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_pe8oDj-sU",
        "outputId": "7cad6436-c0b6-4478-e934-618932b2e9da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7de8774e9800>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: dlopen() error\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Apple_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data = data.sort_values(by='Date', ascending=True)\n",
        "data = data.drop(index=220)\n",
        "def fill_missing_prices(data):\n",
        "    data = data.reset_index(drop=True)\n",
        "    for i in range(len(data)):\n",
        "        if np.isnan(data.loc[i, 'Open Price']) and i > 0:\n",
        "            data.loc[i, 'Open Price'] = data.loc[i - 1, 'Close Price']\n",
        "        if np.isnan(data.loc[i, 'Close Price']) and i < len(data) - 1:\n",
        "            data.loc[i, 'Close Price'] = data.loc[i + 1, 'Open Price']\n",
        "\n",
        "    return data\n",
        "data = fill_missing_prices(data)\n",
        "data = data.dropna()\n",
        "data.head()"
      ],
      "metadata": {
        "id": "XsFbS8OtkBtc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a40780cf-7cb3-4456-9bcd-1203c7b44e05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date company                                           headline  \\\n",
              "0 2022-12-20   Apple  Bans on TikTok Gain Momentum in Washington and...   \n",
              "1 2022-12-20   Apple   Clean Energy Quest Pits Google Against Utilities   \n",
              "2 2022-12-20   Apple  Amazon and E.U. Reach Deal to End Antitrust In...   \n",
              "3 2022-12-21   Apple  YouTube in Advanced Talks for N.F.L. Sunday Ti...   \n",
              "4 2022-12-21   Apple  A New Chat Bot Is a ‘Code Red’ for Google’s Se...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  At least 14 states have passed bans on the ser...   \n",
              "1  Google says its goals for carbon-free power ar...   \n",
              "2  The online retail giant avoided a major fine b...   \n",
              "3  Tech’s biggest companies — Apple, Amazon and Y...   \n",
              "4  A new wave of chat bots like ChatGPT use artif...   \n",
              "\n",
              "                                                 url       section  \\\n",
              "0  https://www.nytimes.com/2022/12/20/technology/...    Technology   \n",
              "1  https://www.nytimes.com/2022/12/20/business/go...  Business Day   \n",
              "2  https://www.nytimes.com/2022/12/20/technology/...    Technology   \n",
              "3  https://www.nytimes.com/2022/12/20/business/nf...  Business Day   \n",
              "4  https://www.nytimes.com/2022/12/21/technology/...    Technology   \n",
              "\n",
              "   Open Price  Close Price  \n",
              "0      130.02       130.92  \n",
              "1      130.02       130.92  \n",
              "2      130.02       130.92  \n",
              "3      131.60       134.04  \n",
              "4      131.60       134.04  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7fffc01-fddb-46f4-a52f-e8e962f0a455\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>company</th>\n",
              "      <th>headline</th>\n",
              "      <th>abstract</th>\n",
              "      <th>url</th>\n",
              "      <th>section</th>\n",
              "      <th>Open Price</th>\n",
              "      <th>Close Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-12-20</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Bans on TikTok Gain Momentum in Washington and...</td>\n",
              "      <td>At least 14 states have passed bans on the ser...</td>\n",
              "      <td>https://www.nytimes.com/2022/12/20/technology/...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>130.02</td>\n",
              "      <td>130.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-12-20</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Clean Energy Quest Pits Google Against Utilities</td>\n",
              "      <td>Google says its goals for carbon-free power ar...</td>\n",
              "      <td>https://www.nytimes.com/2022/12/20/business/go...</td>\n",
              "      <td>Business Day</td>\n",
              "      <td>130.02</td>\n",
              "      <td>130.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-12-20</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Amazon and E.U. Reach Deal to End Antitrust In...</td>\n",
              "      <td>The online retail giant avoided a major fine b...</td>\n",
              "      <td>https://www.nytimes.com/2022/12/20/technology/...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>130.02</td>\n",
              "      <td>130.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-12-21</td>\n",
              "      <td>Apple</td>\n",
              "      <td>YouTube in Advanced Talks for N.F.L. Sunday Ti...</td>\n",
              "      <td>Tech’s biggest companies — Apple, Amazon and Y...</td>\n",
              "      <td>https://www.nytimes.com/2022/12/20/business/nf...</td>\n",
              "      <td>Business Day</td>\n",
              "      <td>131.60</td>\n",
              "      <td>134.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-12-21</td>\n",
              "      <td>Apple</td>\n",
              "      <td>A New Chat Bot Is a ‘Code Red’ for Google’s Se...</td>\n",
              "      <td>A new wave of chat bots like ChatGPT use artif...</td>\n",
              "      <td>https://www.nytimes.com/2022/12/21/technology/...</td>\n",
              "      <td>Technology</td>\n",
              "      <td>131.60</td>\n",
              "      <td>134.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7fffc01-fddb-46f4-a52f-e8e962f0a455')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7fffc01-fddb-46f4-a52f-e8e962f0a455 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7fffc01-fddb-46f4-a52f-e8e962f0a455');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa3dec59-d268-488b-9b4f-2170fff466e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa3dec59-d268-488b-9b4f-2170fff466e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa3dec59-d268-488b-9b4f-2170fff466e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 835,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-12-20 00:00:00\",\n        \"max\": \"2024-12-17 00:00:00\",\n        \"num_unique_values\": 440,\n        \"samples\": [\n          \"2024-03-18 00:00:00\",\n          \"2023-05-09 00:00:00\",\n          \"2024-07-22 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Apple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 813,\n        \"samples\": [\n          \"Markets Remain Anxious, Despite Falling Odds of a Recession\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 814,\n        \"samples\": [\n          \"Some economists are playing down the chances of a downturn. But investors and voters aren\\u2019t feeling nearly as optimistic.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 814,\n        \"samples\": [\n          \"https://www.nytimes.com/2023/09/05/business/dealbook/markets-falling-recession-odds.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Business Day\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.94811071043256,\n        \"min\": 123.72,\n        \"max\": 250.08,\n        \"num_unique_values\": 424,\n        \"samples\": [\n          175.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.004891599889902,\n        \"min\": 123.72,\n        \"max\": 253.48,\n        \"num_unique_values\": 431,\n        \"samples\": [\n          241.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "data['cleaned_headline'] = data['headline'].apply(clean_text)\n",
        "data['cleaned_abstract'] = data['abstract'].apply(clean_text)\n",
        "\n",
        "def get_sentiment(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "data['headline_sentiment'] = data['cleaned_headline'].apply(get_sentiment)\n",
        "data['abstract_sentiment'] = data['cleaned_abstract'].apply(get_sentiment)\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "data['headline_sentiment'] = data['cleaned_headline'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "data['abstract_sentiment'] = data['cleaned_abstract'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "\n",
        "headline_features = vectorizer.fit_transform(data['cleaned_headline'])\n",
        "abstract_features = vectorizer.fit_transform(data['cleaned_abstract'])\n",
        "data['price_change'] = (data['Close Price'] - data['Open Price']) / data['Open Price']\n",
        "\n",
        "X = data[['headline_sentiment', 'abstract_sentiment']]\n",
        "y = data['Close Price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "mape = (abs((y_test - predictions) / y_test.replace(0, 1)).mean()) * 100\n",
        "\n",
        "\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R²: {r2}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "id": "jDDZlAOykCd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4ab503-4811-4332-f662-eac5265bd41c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 23.177875072407804\n",
            "MSE: 820.5922195630922\n",
            "R²: 0.00029425255934123484\n",
            "MAPE: 12.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_vader_sentiment(text):\n",
        "    return sia.polarity_scores(text)['compound']\n",
        "\n",
        "data['headline_sentiment'] = data['headline'].apply(get_vader_sentiment)\n",
        "data['abstract_sentiment'] = data['abstract'].apply(get_vader_sentiment)\n",
        "data['price_increase'] = (data['Close Price'] > data['Open Price']).astype(int)\n",
        "daily_data = data.groupby('Date').agg({\n",
        "    'headline_sentiment': ['mean', 'max', 'count'],\n",
        "    'abstract_sentiment': ['mean', 'max', 'count'],\n",
        "    'Open Price': 'first',\n",
        "    'Close Price': 'last',\n",
        "    'price_increase': 'last'\n",
        "})\n",
        "\n",
        "daily_data.columns = ['_'.join(col).strip() for col in daily_data.columns]\n",
        "daily_data = daily_data.reset_index()\n",
        "X = daily_data[['headline_sentiment_mean', 'headline_sentiment_max', 'headline_sentiment_count',\n",
        "                'abstract_sentiment_mean', 'abstract_sentiment_max', 'abstract_sentiment_count']]\n",
        "y = daily_data['price_increase_last']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "2opaMxe5kE8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d153a195-9f4a-48ca-9c5e-42681613fbb0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5568181818181818\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.29      0.36        38\n",
            "           1       0.58      0.76      0.66        50\n",
            "\n",
            "    accuracy                           0.56        88\n",
            "   macro avg       0.53      0.52      0.51        88\n",
            "weighted avg       0.54      0.56      0.53        88\n",
            "\n",
            "Confusion Matrix:\n",
            " [[11 27]\n",
            " [12 38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_data = daily_data.sort_values('Date')\n",
        "daily_data['Close_Price_lag1'] = daily_data['Close Price_last'].shift(1)\n",
        "daily_data['Close_Price_diff'] = daily_data['Close Price_last'] - daily_data['Close_Price_lag1']\n",
        "daily_data['Close_Price_diff_pct'] = daily_data['Close_Price_diff'] / daily_data['Close_Price_lag1']\n",
        "daily_data = daily_data.dropna()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "gXozrWLLkL-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ade16d9-26a4-47d1-b494-773222d67beb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5568181818181818\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.55      0.52        38\n",
            "           1       0.62      0.56      0.59        50\n",
            "\n",
            "    accuracy                           0.56        88\n",
            "   macro avg       0.56      0.56      0.55        88\n",
            "weighted avg       0.56      0.56      0.56        88\n",
            "\n",
            "Confusion Matrix:\n",
            " [[21 17]\n",
            " [22 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_data = daily_data.sort_values('Date')\n",
        "daily_data['Close_Price_lag1'] = daily_data['Close Price_last'].shift(1)\n",
        "daily_data['Close_Price_diff'] = daily_data['Close Price_last'] - daily_data['Close_Price_lag1']\n",
        "daily_data['Close_Price_diff_pct'] = daily_data['Close_Price_diff'] / daily_data['Close_Price_lag1']\n",
        "daily_data = daily_data.dropna()\n",
        "\n",
        "X = daily_data[['headline_sentiment_mean', 'headline_sentiment_max', 'abstract_sentiment_mean', 'abstract_sentiment_max',\n",
        "                'headline_sentiment_count', 'abstract_sentiment_count', 'Close_Price_diff', 'Close_Price_diff_pct']]\n",
        "y = daily_data['price_increase_last']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2ip_RuD_YPR",
        "outputId": "8b634f9c-a8eb-4f39-db3a-2a0b6b14634b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8409090909090909\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82        36\n",
            "           1       0.90      0.83      0.86        52\n",
            "\n",
            "    accuracy                           0.84        88\n",
            "   macro avg       0.84      0.84      0.84        88\n",
            "weighted avg       0.85      0.84      0.84        88\n",
            "\n",
            "Confusion Matrix:\n",
            " [[31  5]\n",
            " [ 9 43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "pred = best_xgb.predict(X_test)\n",
        "print(\"MAE:\", mean_absolute_error(y_test, pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred))\n",
        "print(\"R²:\", r2_score(y_test, pred))\n",
        "\n",
        "model_lgb = lgb.LGBMRegressor(random_state=42)\n",
        "model_lgb.fit(X_train, y_train)\n",
        "pred_lgb = model_lgb.predict(X_test)\n",
        "print(\"\\nLightGBM Regression:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, pred_lgb))\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_lgb))\n",
        "print(\"R²:\", r2_score(y_test, pred_lgb))\n",
        "\n",
        "model_svr = SVR()\n",
        "model_svr.fit(X_train, y_train)\n",
        "pred_svr = model_svr.predict(X_test)\n",
        "print(\"\\nSVR Regression:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, pred_svr))\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_svr))\n",
        "print(\"R²:\", r2_score(y_test, pred_svr))\n",
        "\n",
        "model_nn = Sequential()\n",
        "model_nn.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model_nn.add(Dropout(0.2))\n",
        "model_nn.add(Dense(32, activation='relu'))\n",
        "model_nn.add(Dense(1))\n",
        "model_nn.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "history = model_nn.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2, verbose=1)\n",
        "pred_nn = model_nn.predict(X_test)\n",
        "print(\"\\nНейронная сеть Regression:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, pred_nn))\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_nn))\n",
        "print(\"R²:\", r2_score(y_test, pred_nn))\n",
        "\n",
        "X_cls = daily_data[['headline_sentiment_mean', 'headline_sentiment_max',\n",
        "                    'abstract_sentiment_mean', 'abstract_sentiment_max',\n",
        "                    'headline_sentiment_count', 'abstract_sentiment_count',\n",
        "                    'Close_Price_diff', 'Close_Price_diff_pct']]\n",
        "y_cls = daily_data['price_increase_last']\n",
        "\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n",
        "\n",
        "model_xgb_cls = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "model_xgb_cls.fit(X_train_cls, y_train_cls)\n",
        "y_pred_xgb_cls = model_xgb_cls.predict(X_test_cls)\n",
        "print(\"\\nXGBoost Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_cls, y_pred_xgb_cls))\n",
        "print(classification_report(y_test_cls, y_pred_xgb_cls))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cls, y_pred_xgb_cls))\n",
        "\n",
        "# CatBoost Classifier\n",
        "model_cat = CatBoostClassifier(random_state=42, verbose=0)\n",
        "model_cat.fit(X_train_cls, y_train_cls)\n",
        "y_pred_cat = model_cat.predict(X_test_cls)\n",
        "print(\"\\nCatBoost Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_cls, y_pred_cat))\n",
        "print(classification_report(y_test_cls, y_pred_cat))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cls, y_pred_cat))\n"
      ],
      "metadata": {
        "id": "qJ7jvqRykNyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097ffdcd-f95e-448b-ea44-16b738ced88c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "Best parameters:  {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
            "MAE: 0.4924755394458771\n",
            "MSE: 0.24904415011405945\n",
            "R²: -0.0026677846908569336\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002483 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 44341\n",
            "[LightGBM] [Info] Number of data points in the train set: 344, number of used features: 384\n",
            "[LightGBM] [Info] Start training from score 0.552326\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "LightGBM Regression:\n",
            "MAE: 0.4901364234959159\n",
            "MSE: 0.2781407479621703\n",
            "R²: -0.11981240496046142\n",
            "\n",
            "SVR Regression:\n",
            "MAE: 0.4825480860992861\n",
            "MSE: 0.2757600850391667\n",
            "R²: -0.11022770407524107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4664 - val_loss: 0.3201\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2082 - val_loss: 0.2978\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1520 - val_loss: 0.3052\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1166 - val_loss: 0.3074\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0966 - val_loss: 0.3141\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.2983\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0789 - val_loss: 0.3054\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0732 - val_loss: 0.3141\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0629 - val_loss: 0.3243\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0506 - val_loss: 0.3124\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0499 - val_loss: 0.3290\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0469 - val_loss: 0.3446\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0439 - val_loss: 0.3413\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.3308\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.3194\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0433 - val_loss: 0.3147\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0351 - val_loss: 0.3346\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0351 - val_loss: 0.3243\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0364 - val_loss: 0.3296\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0353 - val_loss: 0.3271\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - val_loss: 0.3144\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0351 - val_loss: 0.3386\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0331 - val_loss: 0.3336\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.3244\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.3186\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.3200\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.3280\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.3311\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0239 - val_loss: 0.3232\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.3316\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.3263\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.3125\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.3201\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.3211\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.3110\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.3257\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.3091\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.3169\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0196 - val_loss: 0.2999\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.2961\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.2957\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.3016\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.3203\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.3126\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.2982\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.3085\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.3096\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.2945\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.3012\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.3082\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "Нейронная сеть Regression:\n",
            "MAE: 0.5066741108894348\n",
            "MSE: 0.3343680500984192\n",
            "R²: -0.3461873531341553\n",
            "\n",
            "XGBoost Classifier:\n",
            "Accuracy: 0.7954545454545454\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.78      0.78        40\n",
            "           1       0.81      0.81      0.81        48\n",
            "\n",
            "    accuracy                           0.80        88\n",
            "   macro avg       0.79      0.79      0.79        88\n",
            "weighted avg       0.80      0.80      0.80        88\n",
            "\n",
            "Confusion Matrix:\n",
            " [[31  9]\n",
            " [ 9 39]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:18:44] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CatBoost Classifier:\n",
            "Accuracy: 0.8409090909090909\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82        40\n",
            "           1       0.85      0.85      0.85        48\n",
            "\n",
            "    accuracy                           0.84        88\n",
            "   macro avg       0.84      0.84      0.84        88\n",
            "weighted avg       0.84      0.84      0.84        88\n",
            "\n",
            "Confusion Matrix:\n",
            " [[33  7]\n",
            " [ 7 41]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Новая модель, чтобы не запутаться в данных делаем все сначала\n",
        "data = pd.read_csv('Apple_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data = data.sort_values(by='Date', ascending=True)\n",
        "\n",
        "def fill_missing_prices(data):\n",
        "    data = data.reset_index(drop=True)\n",
        "    for i in range(len(data)):\n",
        "        if np.isnan(data.loc[i, 'Open Price']) and i > 0:\n",
        "            data.loc[i, 'Open Price'] = data.loc[i - 1, 'Close Price']\n",
        "        if np.isnan(data.loc[i, 'Close Price']) and i < len(data) - 1:\n",
        "            data.loc[i, 'Close Price'] = data.loc[i + 1, 'Open Price']\n",
        "    return data\n",
        "\n",
        "data = fill_missing_prices(data)\n",
        "data = data.dropna()\n",
        "\n",
        "data['price_increase'] = (data['Close Price'] > data['Open Price']).astype(int)\n",
        "\n",
        "bert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "data['headline_embedding'] = data['headline'].apply(lambda x: bert_model.encode(x))\n",
        "\n",
        "def aggregate_embeddings(embeddings_list):\n",
        "    return np.mean(np.vstack(embeddings_list), axis=0)\n",
        "\n",
        "daily_text = data.groupby('Date')['headline_embedding'].apply(list).reset_index()\n",
        "daily_text['headline_embedding_avg'] = daily_text['headline_embedding'].apply(aggregate_embeddings)\n",
        "\n",
        "embedding_dim = daily_text['headline_embedding_avg'].iloc[0].shape[0]\n",
        "emb_cols = [f'emb_{i}' for i in range(embedding_dim)]\n",
        "emb_df = pd.DataFrame(daily_text['headline_embedding_avg'].tolist(), columns=emb_cols)\n",
        "daily_text = pd.concat([daily_text[['Date']], emb_df], axis=1)\n",
        "\n",
        "daily_price = data.groupby('Date').agg({\n",
        "    'Open Price': 'first',\n",
        "    'Close Price': 'last'\n",
        "}).reset_index()\n",
        "\n",
        "daily_price['SMA_5'] = daily_price['Close Price'].rolling(window=5).mean()\n",
        "daily_price['SMA_10'] = daily_price['Close Price'].rolling(window=10).mean()\n",
        "daily_price['return'] = daily_price['Close Price'].pct_change()\n",
        "\n",
        "daily_price = daily_price.dropna()\n",
        "\n",
        "daily_merged = pd.merge(daily_price, daily_text, on='Date', how='inner')\n",
        "daily_merged['price_increase'] = (daily_merged['Close Price'] > daily_merged['Open Price']).astype(int)\n",
        "\n",
        "feature_cols = ['SMA_5', 'SMA_10', 'return'] + emb_cols\n",
        "X = daily_merged[feature_cols]\n",
        "y = daily_merged['price_increase']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "estimators = [\n",
        "    ('xgb', xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
        "    ('cat', CatBoostClassifier(random_state=42, verbose=0)),\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "]\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "print(\"Ensemble Stacking Classifier Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7vVp3gxvaTk",
        "outputId": "5f489078-2b61-46cc-b5bc-90634234c435"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:25:31] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:27:27] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:27:28] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:27:30] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:27:31] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:27:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Stacking Classifier Results:\n",
            "Accuracy: 0.7931034482758621\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.79        40\n",
            "           1       0.84      0.77      0.80        47\n",
            "\n",
            "    accuracy                           0.79        87\n",
            "   macro avg       0.79      0.80      0.79        87\n",
            "weighted avg       0.80      0.79      0.79        87\n",
            "\n",
            "Confusion Matrix:\n",
            " [[33  7]\n",
            " [11 36]]\n"
          ]
        }
      ]
    }
  ]
}