import io
import logging

import pandas as pd
import requests
import streamlit as st
from streamlit.runtime.uploaded_file_manager import UploadedFile

from util.check_dataset import check_uploaded_data
from util.logging_handler import configure_logger

st.set_page_config(page_title="Predict", page_icon="üîÆ")

logger = configure_logger(__name__, logging.DEBUG)


@st.cache_data
def load_data(file: UploadedFile) -> pd.DataFrame:
    return pd.read_parquet(file)


@st.cache_data
def fetch_inference_space_models():
    response = requests.get(st.session_state.backend_url + "/status")
    if response.status_code != 200:
        logger.error(response.text)
        return []
    logger.debug(response.json())
    return response.json()


@st.cache_data
def predict(model_id, model_type, data):
    parquet_buffer = io.BytesIO()
    data.to_parquet(parquet_buffer, index=False)
    parquet_buffer.seek(0)

    files = {
        "file": ("data.parquet", parquet_buffer, "application/octet-stream")
    }
    payload = {"id": model_id, "model_type": model_type}

    response = requests.post(
        st.session_state.backend_url + "/predict",
        data=payload,
        files=files
    )

    if response.status_code != 200:
        logger.error(response.text)
        return []

    logger.debug(response.json())
    return response.json()


st.markdown("# –°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
st.sidebar.header("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
st.write(
    """–ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –ø–æ–º–µ—â—ë–Ω–Ω–æ–π –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏.
    –î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø—É–Ω–∫—Ç –º–µ–Ω—é.""")

model_type = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –º–æ–¥–µ–ª–∏", ("Social üßª", "News üì∞"))
model_type_normalized = "social" if model_type == "Social üßª" else "news"

st.write(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ parquet-—Ñ–∞–π–ª —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", type=["parquet"])

if uploaded_file:
    df = load_data(uploaded_file)
    correct, error_message = check_uploaded_data(df, model_type)
    if correct:
        st.write("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã!")
    else:
        st.error(error_message)

    models = fetch_inference_space_models()['models']

    model_id = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", list(models.keys()))

    predict_button = st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")

    if predict_button:
        st.write("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:")
        prediction = predict(model_id, model_type_normalized, df)

        st.json(prediction)
